{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Q1\n",
    "wine = np.array(pd.read_csv(\"data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Q2\n",
    "# x = np.linspace(1, wine[0].size, wine[0].size)\n",
    "# for i in range(100):    \n",
    "#     plt.scatter(x, wine[i])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "data, labels = np.split(wine, [wine[0].size-1], axis=1)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 13)\n",
      "(1200, 13)\n",
      "(4800, 1)\n",
      "(1200, 1)\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "x_train, x_valid = np.split(data, [int(data.shape[0]*0.8)])\n",
    "labels_train, labels_valid = np.split(labels, [int(labels.shape[0]*0.8)])\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Q5\n",
    "num_train_samples = [100,200,500,1000,2000,4800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.264166666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.8375\n",
      "SAMPLE SIZE:  1000 , Performance: 0.948333333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.98\n",
      "SAMPLE SIZE:  4800 , Performance: 0.98\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "for train_size in num_train_samples:\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train[:train_size], labels_train[:train_size].ravel())\n",
    "    print(\"SAMPLE SIZE: \", train_size, \", Performance:\", clf.score(x_valid, labels_valid.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- USING: l1 ---\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.266666666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.978333333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.975833333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.984166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.988333333333\n",
      "--- USING: l2 ---\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.264166666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.8375\n",
      "SAMPLE SIZE:  1000 , Performance: 0.945833333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.98\n",
      "SAMPLE SIZE:  4800 , Performance: 0.98\n",
      "\n",
      "L1 does better, because it has learned better to ignore certain features because it drives those features to 0 weight\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "for pen in ['l1','l2']:\n",
    "    print(\"--- USING:\",pen,\"---\")\n",
    "    for train_size in num_train_samples:\n",
    "        clf = LogisticRegression(penalty=pen)\n",
    "        clf.fit(x_train[:train_size], labels_train[:train_size].ravel())\n",
    "        print(\"SAMPLE SIZE: \", train_size, \", Performance:\", clf.score(x_valid, labels_valid.ravel()))\n",
    "\n",
    "print(\"\\nL1 does better, because it has learned better to ignore certain features because it drives those features to 0 weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01\n",
      "SAMPLE SIZE:  100 , Performance: 0.263333333333\n",
      "SAMPLE SIZE:  200 , Performance: 0.263333333333\n",
      "SAMPLE SIZE:  500 , Performance: 0.273333333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.8825\n",
      "SAMPLE SIZE:  2000 , Performance: 0.94\n",
      "SAMPLE SIZE:  4800 , Performance: 0.943333333333\n",
      "C = 0.03\n",
      "SAMPLE SIZE:  100 , Performance: 0.263333333333\n",
      "SAMPLE SIZE:  200 , Performance: 0.263333333333\n",
      "SAMPLE SIZE:  500 , Performance: 0.818333333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.925\n",
      "SAMPLE SIZE:  2000 , Performance: 0.945833333333\n",
      "SAMPLE SIZE:  4800 , Performance: 0.970833333333\n",
      "C = 0.1\n",
      "SAMPLE SIZE:  100 , Performance: 0.400833333333\n",
      "SAMPLE SIZE:  200 , Performance: 0.264166666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.760833333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.925\n",
      "SAMPLE SIZE:  2000 , Performance: 0.974166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.98\n",
      "C = 0.3\n",
      "SAMPLE SIZE:  100 , Performance: 0.74\n",
      "SAMPLE SIZE:  200 , Performance: 0.263333333333\n",
      "SAMPLE SIZE:  500 , Performance: 0.860833333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.965833333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.978333333333\n",
      "SAMPLE SIZE:  4800 , Performance: 0.980833333333\n",
      "C = 1\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.266666666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.979166666667\n",
      "SAMPLE SIZE:  1000 , Performance: 0.975833333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.984166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.988333333333\n",
      "C = 3\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.94\n",
      "SAMPLE SIZE:  500 , Performance: 0.8375\n",
      "SAMPLE SIZE:  1000 , Performance: 0.979166666667\n",
      "SAMPLE SIZE:  2000 , Performance: 0.985\n",
      "SAMPLE SIZE:  4800 , Performance: 0.988333333333\n",
      "C = 10\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.826666666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.833333333333\n",
      "SAMPLE SIZE:  1000 , Performance: 0.925\n",
      "SAMPLE SIZE:  2000 , Performance: 0.985\n",
      "SAMPLE SIZE:  4800 , Performance: 0.989166666667\n",
      "C = 30\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.775833333333\n",
      "SAMPLE SIZE:  500 , Performance: 0.951666666667\n",
      "SAMPLE SIZE:  1000 , Performance: 0.849166666667\n",
      "SAMPLE SIZE:  2000 , Performance: 0.985\n",
      "SAMPLE SIZE:  4800 , Performance: 0.988333333333\n",
      "C = 50\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.750833333333\n",
      "SAMPLE SIZE:  500 , Performance: 0.969166666667\n",
      "SAMPLE SIZE:  1000 , Performance: 0.903333333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.984166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.988333333333\n",
      "C = 100\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.9725\n",
      "SAMPLE SIZE:  1000 , Performance: 0.923333333333\n",
      "SAMPLE SIZE:  2000 , Performance: 0.984166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.9875\n",
      "C = 300\n",
      "SAMPLE SIZE:  100 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  200 , Performance: 0.736666666667\n",
      "SAMPLE SIZE:  500 , Performance: 0.9725\n",
      "SAMPLE SIZE:  1000 , Performance: 0.8325\n",
      "SAMPLE SIZE:  2000 , Performance: 0.984166666667\n",
      "SAMPLE SIZE:  4800 , Performance: 0.9875\n",
      "\n",
      "C should be higher here, so I will go with a value of 50\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "#Q7\n",
    "for c in [0.01,0.03,0.1,0.3,1,3,10,30,50,100,300]:\n",
    "    print(\"C =\",c)\n",
    "    for train_size in num_train_samples:\n",
    "        clf = LogisticRegression(penalty='l1',C=c)\n",
    "        clf.fit(x_train[:train_size], labels_train[:train_size].ravel())\n",
    "        print(\"SAMPLE SIZE: \", train_size, \", Performance:\", clf.score(x_valid, labels_valid.ravel()))\n",
    "        \n",
    "print(\"\\nC should be higher here, so I will go with a value of\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Q9\n",
    "# optimal LR that I found\n",
    "test = np.array(pd.read_csv(\"test.csv\"))\n",
    "\n",
    "ids = np.linspace(0,test.shape[0]-1, test.shape[0])\n",
    "\n",
    "clf = LogisticRegression(penalty='l1',C=50)\n",
    "clf.fit(data, labels.ravel()) #give all the data\n",
    "# print(\"SAMPLE SIZE: \", data.shape[0], \", Predictions:\", )\n",
    "pred = clf.predict(test);\n",
    "ids = np.reshape(ids, (ids.shape[0],1))\n",
    "pred = np.reshape(pred, (ids.shape[0],1))\n",
    "out = np.concatenate((ids, pred), axis=1)\n",
    "out = out.astype(int)\n",
    "np.savetxt(\"predictions.csv\", out, fmt='%i', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
